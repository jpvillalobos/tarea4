---
title: "Tarea 4 - Mineria de Datos e Inteligencia de Negocios"
author: "Jonathan Gonzalez, Gonzalo Rodriguez, Juan P. Villalobos"
date: "05/17/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
#instalar librerias
options(repos="https://cran.rstudio.com" )

#install.packages("evaluate")
#install.packages("tibble")
#install.packages("stringr")
#install.packages("rvest")
#install.packages("FactoMineR")
#install.packages("ggplot2")
#install.packages("purrr")
#install.packages("dplyr")
#install.packages("cluster")
#install.packages("factoextra")
#install.packages("knitr")
#install.packages("fpc")
#install.packages("foreign")
#install.packages("GGally")
#install.packages("kableExtra")
#install.packages("dendextend")
#install.packages("clValid")
#install.packages("NbClust")



# knitr::opts_chunk$set(echo = TRUE)

# cargar librerias necesarias
suppressWarnings(suppressMessages(library(tibble)))
suppressWarnings(suppressMessages(library(stringr)))
suppressWarnings(suppressMessages(library(rvest)))
suppressWarnings(suppressMessages(library(FactoMineR)))
suppressWarnings(suppressMessages(library(ggplot2)))
suppressWarnings(suppressMessages(library(purrr)))
suppressWarnings(suppressMessages(library(dplyr)))
suppressWarnings(suppressMessages(library(cluster)))
suppressWarnings(suppressMessages(library(factoextra)))
suppressWarnings(suppressMessages(library(knitr)))
suppressWarnings(suppressMessages(library(fpc)))
suppressWarnings(suppressMessages(library(foreign)))
suppressWarnings(suppressMessages(library(GGally)))
suppressWarnings(suppressMessages(library(kableExtra)))
suppressWarnings(suppressMessages(library(dendextend)))
suppressWarnings(suppressMessages(library(clValid)))
suppressWarnings(suppressMessages(library(NbClust)))
```
# Web Mining y Clustering
___
## Objetivos

### Negocio
* Ejercicio Académico.

> Construir clusters de los jugadores mas valiosos de la NBA segun su porcentaje de efectividad en tiros.

### Minería de Datos
* Desarrollar un modelo utilizando reglas de clustering.

* Aplicar parcialmente la metodología CRISP-DM para resolver un caso básico de minería de datos.

* Extraer datos de una página web para ser analizados posteriormente.

* Aplicar expresiones regulares para procesar datos textuales.

* Aplicar un algoritmo de clustering a los datos extraídos.

### Criterio de éxito

* Aplicar los conceptos vistos en clase correctamente.

## Entendimiento de los datos

### Exploración de datos

* ***Busque en Internet una página web con datos que sean de su interés. Los datos deben ser parte de lo que la página presenta, es decir, deben ser tablas, párrafos, etc. visibles al cargar la página.***

Para la presente tarea se utilizarán las siguientes páginas web:

* Estadísticas de los jugadores mas valiosos de la NBA y ABA (MVPs) según Basketball Reference:
[https://www.basketball-reference.com/awards/mvp.html](https://www.basketball-reference.com/awards/mvp.html)

* Información de jugadores mas valiosos de la NBA (MVPs) según Wikipedia:
[https://en.wikipedia.org/wiki/NBA_Most_Valuable_Player_Award](https://en.wikipedia.org/wiki/NBA_Most_Valuable_Player_Award)


```{r}
#leer los datos en formato html desde las paginas web, Wiki Basketball MVP
NBA_MVP_pageURL<-'https://www.basketball-reference.com/awards/mvp.html'
Wiki_MVP_pageURL<-'https://en.wikipedia.org/wiki/NBA_Most_Valuable_Player_Award'
nba_pageHTML<- read_html(NBA_MVP_pageURL,encoding = 'UTF-8')
wiki_pageHTML<- read_html(Wiki_MVP_pageURL,encoding = 'UTF-8')
  
#extraer las tablas del codigo html
nba_pageTables<- html_table(nba_pageHTML,fill=TRUE)
wiki_pageTables<- html_table(wiki_pageHTML,fill=TRUE)
```

#### Exploración de datos de www.basketball-reference.com

La página de Basketball Reference tiene: ```r length(nba_pageTables)``` tablas, cuyos encabezados son:

```{r}
#mostrar los encabezados de cada tabla
str(nba_pageTables)
```

> El resultado anterior muestra un error en los encabezados de las tablas debido al estilo del sitio web. Además se aprecia que las dos primeras tablas deben unirse y que, debido a estadísticas faltantes, procederemos a ignorar/eliminar la tercera para el ejercicio de clustering.

La cantidad de datos vacíos en la tabla #1 es: ```r sum(nba_pageTables[[1]] == "")```  
La cantidad de datos vacíos en la tabla #2 es: ```r sum(nba_pageTables[[2]] == "")```

> Esta cantidad de datos vacíos nos indica que los datos deben limpiarse un poco antes de ser procesados.

#### Exploración de datos de Wikipedia

La página de NBA tiene: ```r length(wiki_pageTables)``` tablas, cuyos encabezados son:

```{r}
#mostrar los encabezados de cada tabla
str(wiki_pageTables) 
```

> El resultado anterior nos muestra que los datos a extraer están en la tabla número 6 y que sus encabezados no necesitan limpieza adicional.

La cantidad de datos vacios en la tabla #6 es: ```r sum(wiki_pageTables[[6]] == "")```  

> Esta cantidad de datos vacios nos indica una alta calidad en los datos.


### Preparación de los datos

* ***Seleccione los datos de su interés en las páginas previamente identificadas.***
```{r}
#agregar y almacenar la tablas #1 y #2 de la NBA
nba_Table<- nba_pageTables[[1]]

#seleccionar la primera fila como encabezados.
names(nba_Table) <- nba_Table[1,]

#almacenar la tabla #3 de la pagina de Wiki, no necesita cambios por el momento.
wiki_Table<- wiki_pageTables[[6]]

kable(nba_Table)
kable(wiki_Table)
```


* ***Limpieza de los datos: limpie lo que sea necesario aplicando expresiones regulares.***

> Según la vista  anterior se observa que de la tabla nba_table debe eliminarse la primera fila pues contiene el encabezado. También se decide que las columnas "Age" (la edad del jugador), "lg" (el nombre de la liga) y "voting" (que es un enlace a otra página con el desglose de las votaciones por el MVP de la temporada) no serán utilizadas para hacer el clustering de la información. De igual forma se eliminarán las columnas WS y WS/48 (win shares y win shares by 48 minutes, respectivamente) puesto que al ser "métricas avanzadas" utilizan las otras estadísticas como parte de su cálculo, es decir, introducen una dependencia lineal.

> Con respecto a la tabla wiki_table se observa que que deben ser removidas las columnas Team y Nationality pues no son de utilidad para el análisis. La columna "Player" tambien debe eliminarse porque está duplicada en la tabla nba_table

```{r}
# Eliminar las columnas: "Age", "G", Lg", "Voting", "Tm", "WS", "WS/48" del frame nba_Table pues no aportan datos importantes al modelo.
nba_Table$Age <- NULL
nba_Table$G <- NULL
nba_Table$Lg <- NULL
nba_Table$Voting <- NULL
nba_Table$Tm <- NULL
nba_Table$WS <- NULL
nba_Table$"WS/48" <- NULL

# Eliminar las filas que contienen encabezados como datos (busca un encabezado dentro de los datos)
nba_Table<- nba_Table[ grep("Season", nba_Table$Season, invert = TRUE) , ]

kable(nba_Table)

# Eliminar las columnas: "Player" del frame wiki_Table (ya está en la otra tabla), Nationality y Team (no serán tomadas en cuenta para el análisis)
wiki_Table$Player <- NULL
wiki_Table$Nationality <- NULL
wiki_Table$Team <- NULL

# Reemplazar caracteres invalidos para "-" en el campo "Season". (Sí, son diferentes).
wiki_Table$Season <- str_replace(wiki_Table$Season,'\\–','\\-')

kable(wiki_Table)
```

* ***Construcción de nuevos datos (atributos). Si no aplica, indíquelo. Si construye nuevas columnas o atributos, explique.***

> No se contruirán nuevos atributos, sin embargo en esta fase se unirán los datos de ambas páginas utilizando el campo común "Season".

```{r}
# Unir ambas tablas en una sola con todos los atributos.
players_table <- merge(nba_Table,wiki_Table, by = "Season")

# Reorganizar la posición de las columnas para facilitar la visualización
players_table<- players_table[c(1,2,12,3,4,5,6,7,8,9,10,11)]

kable(players_table)

```

* ***Transformaciones aplicadas a los datos. Describa las transformaciones realizadas.***

> Primero se reemplaza los nombres de las filas del dataframe por una combinación de las columnas Season, Player y Position para facilitar la lectura de los resultados. Una vez realizado este cambio esas columnas se eliminan.

```{r}
players_table$id <- paste(players_table$Player,'(',players_table$Season,')','-',players_table$Position)
rownames(players_table) <- players_table$id

players_table$id <- NULL
players_table$Player <- NULL
players_table$Season <- NULL
players_table$Position <- NULL

kable(players_table)

```

> Luego se aplica una transformación básica, mutar las columnas a valores numéricos. Luego se procede a eliminar las filas con valores vacíos: un total de 24 que comprenden aquellas temporadas previas a 1979-1980 cuando no se llevaba registro de estadísticas como robos, bloqueos y el tiro de 3 puntos no existía. Finalmente se normalizan las columnas numéricas para evitar que las diferencias en magnitudes perjudiquen el modelo.

```{r}

# Transformar las columnas con valores númericos a su correspondiente tipo.
sapply(players_table, class)

numeric_columns <- c(1:9)
players_table[ , numeric_columns] <- apply(players_table[ , numeric_columns], 2,  # Especifica la funcion en la llamada
                                           function(x) as.numeric(as.character(x)))
sapply(players_table, class)
kable(players_table)

# Eliminar filas con valores vacíos
na_omitted <- na.omit(players_table) 
kable(na_omitted)

# Normalizacion de los datos
# players_normal <- na_omitted %>% mutate_at(1:10, funs((. - mean(.))/sd(.)))
players_normal <- as.data.frame(scale(na_omitted))
kable(players_normal)

```


### Fase de modelado

***Para esta fase se le solicita que seleccione dos de los algoritmos de clustering vistos en clase, o bien ejecutar dos veces sólo uno de los algoritmos estudiados pero usando diferentes parámetros cada vez.***

> Las técnicas a utilizar son k-means y clustering jerárquico. Haremos dos ejecuciones de k-means y una de clustering jerárquico.

#### Construcción de modelo k-means (5,20)

Los parámetros a utilizar para la primera ejecución son: k = 5 centroides: haciendo uso de nuestro modesto conocimiento previo de los datos y conscientes de que existen 5 posiciones diferentes en el baloncesto. nstart = 20 configuraciones iniciales: aprovechando el reducido tamaño del set de datos.
    
```{r}

# ejecución del algoritmo kmeans con los parámetros elegidos
clusters <- kmeans(players_normal,5,nstart=20)

# obtener cantidad de registros en cada cluster y los centroides
descClusters<- data.frame(clusters$size,clusters$centers)
kable(descClusters)

# crear un data frame combinando el cluster asignado y los atributos originales
resultado <- data.frame(clusters$cluster,players_normal)
names(resultado)[1] <- "cluster"
kable(resultado[order(resultado$cluster),])
```  
    
* ***Descripción del modelo obtenido (incluya al menos un gráfico por modelo)***

> La ejecución del modelo nos da como resultado 4 clusters de entre 4 y 9 elementos y otro cluster de 14 elementos. 

> Podemos notar que el modelo suele agrupar jugadores que juegan las mismas o similares posiciones en el mismo cluster. Esto tiene mucho sentido puesto que estos jugadores suelen tener valores similares en las mismas estadísticas: centers y power forwards acumulan muchos rebotes (TRB) y bloqueos (BLK), point guards lideran en asistencias (AST) y robos (STL), shooting guards suelen ser buenos anotadores (TP).

> A continuación, el primer gráfico nos muestra la distribución de los jugadores en los distintos clusters:

```{r}
plotcluster(players_normal, clusters$cluster)

```

> El segundo gráfico nos muestra el aporte o influencia de cada una de las dimensiones para la clasificación de los jugadores, cada línea representa a un jugador y está coloreada de acuerdo al cluster en el que fue colocado. En el eje x se pueden ver los nombres de las dimensiones con su magnitud representada en el eje y. De acuerdo a lo explicado en la descripción del modelo obtenido podemos notar como las estadisticas PTS, TRB, AST, STL y BLK son las más importantes para el modelo, mientras que FT, MP y sorprendentemente X3P (porcentaje de tiros de 3 puntos) no tienen tanta variación en sus valores y por lo tanto no son tan valiosas para el agrupamiento.

```{r}
ggparcoord(data=resultado,columns=2:10, groupColumn=1,mapping=aes(color=as.factor(cluster)))

```  

Cálculo de los valores óptimos de K


```{r}
# evaluacion modelo #1
# cálculo del score Silhouette
score_sil<- silhouette(clusters$cluster,daisy(players_normal))

# cálculo del valor óptimo de k usando el score silhouette
fviz_nbclust(players_normal,kmeans,method = 'silhouette',k.max = 10)
```

> El método "Average silhouette" determina el número óptimo de clusters k=2, donde se maximiza el valor de la silueta con respecto a un rango de valores k.

```{r}
# cálculo del valor óptimo de k usando el método del codo
fviz_nbclust(players_normal,kmeans,method = 'wss',k.max = 10)
```

> Evaluando la curva de la suma de cuadrados, podemos apreciar que en 2, 3, y 5 se encuentra levemente la figura que busca el método del "codo", aunque es subjetivo, en el punto donde se dobla la linea es considerado como un buen indicar para estimar el número apropiado de clusters.


```{r}
# cálculo del valor óptimo de k usando la estadística gap
fviz_nbclust(players_normal,kmeans,method = 'gap_stat',k.max = 10)

```

> "Statistic gap" compara el total de variación intra-cluster, para diferentes valores de k, el valor óptimo que maximiza el espacio estadístico, esto significa que la estructura del cluster esta lejos de una distribución uniforme de puntos aleatorios.


```{r}
NbClust(data = players_normal, diss = NULL, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans")
```


#### Construcción de modelo k-means (2,20)

Los parámetros a utilizar son: k = 2 centroides, siguiendo la recomendación dada por silhouette para el primer modelo. nstart = 15 configuraciones iniciales, aprovechando el tamaño del set de datos y la reducción en la cantidad de centroides a utilizar.
    
```{r}

# ejecución del algoritmo kmeans con los parámetros elegidos
clusters2 <- kmeans(players_normal,2,nstart=15)

# obtener cantidad de registros en cada cluster y los centroides
descClusters2<- data.frame(clusters2$size,clusters2$centers)
kable(descClusters2)

# crear un data frame combinando el cluster asignado y los atributos originales
resultado2 <- data.frame(clusters2$cluster,players_normal)
names(resultado2)[1] <- "cluster"
kable(resultado2[order(resultado2$cluster),])
```

* ***Descripción del modelo obtenido (incluya al menos un gráfico por modelo)***

> La ejecución del modelo nos da como resultado 2 clusters de 27 y de 13 elementos.

> A diferencia del primer modelo de k=5, éste utiliza los rebotes (TRB), asistencias (AST), robos (STL) y bloqueos (BLK) como las dimensiones más importantes para el agrupamiento. Con mucha seguridad, incluso antes de ver el dataframe "resultado2", podríamos concluir que el algoritmo está dividiendo entre bases (point guard, shooting guard, small foward) y aleros (power forward y center). También se le llama a esta diferenciación "hombres pequeños" y "hombres grandes", respectivamente.

> A continuación, el primer gráfico nos muestra la distribución de los jugadores en los distintos clusters:

```{r}

plotcluster(players_normal, clusters2$cluster)
```

> El segundo gráfico nos muestra el aporte o influencia de cada una de las dimensiones para la clasificación de los jugadores, cada línea representa a un jugador y está coloreada de acuerdo al cluster en el que fue colocado. La única diferencia de este gráfico respecto al producido por el modelo anterior es obviamente la cantidad de colores/clusters.

```{r}
ggparcoord(data=resultado2,columns=2:10, groupColumn=1,mapping=aes(color=as.factor(cluster)))

```  


#### Construcción de modelo Jerárquico

Reconocido como uno de los modelos más utilizados en agrupaciones de objectos, con base en su similitud.  Tambien es conocido como AGNES (Agglomerative Nesting).  El algoritmo inicia tratando cada objecto como un cluster único. Luego, crea parejas de clusters que son combinadas, hasta que todos se hayan constituido en un gran cluster conteniendo todos los objetos.  El resultado es una representación tipo árbol de todos los elementos, llamado dendrogram.

De esta forma el algoritmo funciona como "bottom-up", inicia en las hojas, donde cada elemento es un cluster por si mismo y continua haciendo agregaciones.  En cada paso, los dos clusters con mayor similitud son combinados en un cluster de mayor altura en la jerarquía.  El proceso se repite hasta que se obtiene un único cluster raíz.

* Cálculo de la matriz de distancias euclidianas.
```{r}
# se calculan las distancias entre los puntos
    dist_matrix<- dist(players_normal,method = 'euclidean')
    as.matrix(dist_matrix)[1:10, 1:10]
```

> Para poder decidir cuales objectos o clusters deben ser combinados o divididos, necesitamos mecanismos para medir la similitud entre objectos.  En este caso utilizaremos la distancia euclideana, como una alternativa podríamos utilizar la distancia manhattan.  En R, se puede utilizar la funcion dist() para computar la distancia entre cada par de objetos en el conjunto de datos.  Los resultados de este procesamiento es conocido como matriz de disimilitudes.  e.g.: dist_matrix

* Ejecución del modelo (usando el método "average")
```{r}
# se establece el criterio de linkage y se ejecuta el clustering
clustJer_conAvg<- hclust(dist_matrix,method = 'ward.D')

```

> La funcion de enlace toma la informacion de la distancia, retornada por la funcion dist(), y agrupa pares de objetos dentro de clusters con base en su similitud.  Algunas variantes para el método disponibles en la función hclust son: “ward.D”, “ward.D2”, “single”, “complete”, “average”, “mcquitty”, “median” o “centroid”.

##### Visualización del cluster

```{r fig.align='center', fig.height=8}

# dendrograma del clustering  usando average
plot(clustJer_conAvg)
```

> Debido a la naturaleza del algorimo, es esperado que un jugador que sea nominado múltiples años, inicie formando un cluster consigo mismo, en otra temporada, siempre y cuando sus estadisticas sean consistentes.  De hecho se puede apreciar este efecto en jugadores como LeBron llegando a formar 2 niveles, combinandose el mismo en dos ocasiones. Es muy comun ese patrón en el primer nivel.


```{r fig.align='center'}
dendrograma<-as.dendrogram(clustJer_conAvg)
color_dendro<- color_branches(dendrograma,k=5)
plot(color_dendro)
```

##### DIvisive clustering

Existe una version "top-down" que inicia en la raíz llamado "divisive clustering", donde el cluster más heterogeneo es dividido en dos, y el proceso continua hasta obtener las hojas.

```{r fig.align='center'}
# DIvisive ANAlysis Clustering
res.diana <- diana(x = players_normal, # data matrix
                   stand = TRUE, # standardize the data
                   metric = "ward.D2" # metric for distance matrix
                   )
#fviz_dend(res.diana, cex = 0.5)
#plot(res.diana)
dendrograma <- as.dendrogram(res.diana)
color_dendro<- color_branches(dendrograma,k=5)
plot(color_dendro)
```


* ***Evaluación de los modelos ***

Los modelos obtenidos utilizando k-means arrojan resultados muy similares a los que una persona "manualmente" realizaría: separar a los jugadores por "roles" (k=2) o por posición (k=5), con la salvedad de que el algoritmo obviamente desconoce estas clasificaciones prácticas y utiliza únicamente las estadísticas para agrupar, lo que explica por que existen algunos "intrusos" en grupos en los que, según su posición, no corresponderían. Dirk Nowitzki es por supuesto el mejor ejemplo de esta "equivocación" al encontrarse en un grupo que con coincide con su posición, pero conociendo la carrera del jugador alemán uno sabe que nunca fue un "hombre grande" tradicional; al contrario se caraterizaba por su efectivo tiro desde el exterior y zona de 3 puntos y su pobre desempeño en estadísticas tradicionales de los power forwards: rebotes y bloqueos.

Los modelos k-means nos brindan resultados muy claros pues se basan en una interpretación muy directa/simple de las estadísticas. Esto claramente es deseable cuando se requiera agrupar de forma simple un gran número de elementos con una cantidad de dimensiones no trivial.

El modelo jerárquico realiza un agrupamiento menos intuitivo: coloca a Shaquille O'Neal como el miembro único de su cluster, une a Allen Iverson y la primera temporada de MVP de Michael Jordan en otro cluster, luego agrupa de forma similar a los métodos k-means: aleros y bases.